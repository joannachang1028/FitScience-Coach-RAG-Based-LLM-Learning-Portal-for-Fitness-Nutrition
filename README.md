# FitScience Coach - Personal Learning Portal

An evidence-based fitness and nutrition learning portal powered by RAG (Retrieval-Augmented Generation) technology.

## ğŸ¯ Project Overview

**FitScience Coach** helps users learn evidence-based fitness and nutrition through:
- Interactive Q&A with citations
- Curated learning corpus from academic papers, guidelines, and expert podcasts
- Progress tracking and personalized recommendations
- Modular learning paths covering training, nutrition, and health

## ğŸ“š Learning Objectives

1. **Design** a weekly training plan with progression, rest, and goal alignment
2. **Synthesize** nutrition targets (protein, carbs, fat, calories) with training goals, lifestyle, and preferences  
3. **Identify** food choices to meet daily calorie and micronutrient needs (vitamins, minerals)
4. **Calculate** daily calorie consumption based on body goals (fat loss, muscle gain, maintenance) using BMR and NEAT data

## ğŸ—ï¸ System Architecture

```
User Query â†’ RAG Pipeline â†’ Vector Search â†’ LLM Generation â†’ Response + Citations
```

### Components:
- **Corpus**: 23 evidence-based sources (papers, guidelines, podcasts)
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Vector Store**: FAISS for fast similarity search
- **LLM**: Hybrid approach - OpenAI GPT-4o-mini (primary) + Llama 3.2 1B (fallback)
- **Interface**: Streamlit web app

### Performance:
- **RAGAs Score**: 0.857 (Excellent) â­â­â­â­â­
- **Retrieval Metrics**: Perfect 1.0 across all dimensions
- **Faithfulness**: 0.429 (286% improvement through optimization)

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Set Environment Variables (Optional)
```bash
export OPENAI_API_KEY="your-api-key-here"
```

### 3. Run the Streamlit App
```bash
streamlit run src/streamlit_app.py
```

### 4. Access the Interface
Open your browser to `http://localhost:8501`

## ğŸ“Š Learning Corpus

The system uses a curated corpus of 23 evidence-based sources:

### Source Types:
- **Academic Papers**: Protein requirements, BMR calculations, training volume
- **Guidelines**: ACSM position stands, NSCA recommendations  
- **Government Resources**: USDA MyPlate, NIH fact sheets, NHS programs
- **Expert Content**: Jeff Cavaliere (Athlean-X), Diary of a CEO podcast episodes
- **Research Reviews**: Micronutrients, NEAT, sleep and performance

### Key Domains Covered:
- âœ… Training programming and progression
- âœ… Macronutrient targets and timing
- âœ… Micronutrient needs and sources
- âœ… Calorie calculation (BMR, TDEE, NEAT)
- âœ… Sleep and recovery optimization
- âœ… Evidence-based supplementation

## ğŸ¤– Features

### Ask Coach Tab
- Interactive Q&A with evidence-based answers
- Automatic source citations and links
- Quick question buttons for common topics
- Query history tracking

### Learning Goals Tab
- Clear learning objectives and questions
- Progress tracking metrics
- Module completion status

### Corpus Explorer Tab
- Browse and filter all sources
- Search by keywords
- View source metadata and links

### Query History Tab
- Track all interactions
- Export conversation history
- Review past questions and answers

## ğŸ”§ Technical Details

### RAG Pipeline (`src/rag_pipeline.py`)
```python
# Initialize system
from src.rag_pipeline import FitScienceRAG

rag = FitScienceRAG()
rag.initialize_system()

# Query the system
result = rag.query("How much protein should I eat?")
```

### Key Classes:
- `FitScienceRAG`: Main RAG system class
- Handles corpus loading, embedding, and retrieval
- Supports both OpenAI and retrieval-only modes

### Vector Store:
- **Embeddings**: HuggingFace sentence-transformers
- **Storage**: FAISS for fast similarity search
- **Chunking**: 1000 chars with 200 overlap

## ğŸ“ˆ Evaluation

The system supports evaluation using:
- **RAGAs**: Measure factuality, groundedness, context recall
- **ARES**: Alternative evaluation framework
- **Manual Assessment**: Review answer quality and source relevance

## ğŸ“ Assignment 3 Deliverables

| Deliverable | Location |
|-------------|----------|
| **System Code** | `src/rag_pipeline.py`, `src/streamlit_app.py` |
| **Learning Corpus** | `data/learning_corpus.csv` (23 sources) |
| **PLP Interface** | `src/streamlit_app.py` (Streamlit app) |
| **Evaluation Script** | `src/ragas_evaluation_v3.py` |
| **Evaluation Results** | `ragas_results/ragas_evaluation_results.json` (Score: 0.857) |
| **Evaluation Log** | `reports/Evaluation_Log_and_Samples.md` |
| **Final Report** | `reports/Final_Report.md` |
| **System Architecture** | `diagrams/system_architecture.md` |
| **Step Documentation** | `reports/Domain_Learning_Goals.md`, `reports/PLP_Features_To_Adopt.md` |
| **GitHub Repository** | [Ready for submission] |

## ğŸ”® Future Enhancements

### Optional Bonus Features:
- **Reasoning Agents**: Chain-of-thought reasoning for complex queries
- **Multi-Agent Workflow**: Planner â†’ Searcher â†’ Summarizer pipeline
- **Knowledge Graph**: Neo4j integration for concept relationships

### Additional Features:
- User profile and goal tracking
- Personalized plan generation
- Integration with fitness tracking apps
- Advanced evaluation metrics

## ğŸ“Š Evaluation & Performance

### RAGAs Automated Evaluation

**Final Score: 0.857 / 1.0 (Excellent) â­â­â­â­â­**

| Metric | Score | Status |
|--------|-------|--------|
| Context Precision | 1.000 | â­â­â­â­â­ Perfect |
| Context Recall | 1.000 | â­â­â­â­â­ Perfect |
| Context Relevance | 1.000 | â­â­â­â­â­ Perfect |
| Faithfulness | 0.429 | â­â­â­â­ Good |
| **Overall** | **0.857** | â­â­â­â­â­ **Excellent** |

### Iterative Improvement Journey

1. **v1.0** (Llama 3.2 1B): 0.779 - Good baseline, perfect retrieval
2. **v2.0** (Optimized Llama): 0.778 - Optimization attempts showed model limitations
3. **v3.0** (OpenAI GPT-4o-mini): **0.857** - 286% faithfulness improvement

**Key Learning**: Model selection is critical for faithfulness. Perfect retrieval validates corpus design.

### Run Evaluation
```bash
python src/ragas_evaluation_v3.py
```

## ğŸ“ Usage Examples

### Sample Queries:
1. "How much protein should I eat for muscle building?"
2. "How do I calculate my daily calorie needs?"
3. "What is progressive overload in training?"
4. "What supplements are actually evidence-based?"
5. "How much sleep do I need for recovery?"

### Expected Output:
- Evidence-based answers with practical advice
- Source citations with links to original papers
- Relevance scores and content previews
- Structured, actionable recommendations

## ğŸ¤ Contributing

This is an academic project for Assignment 3. For improvements:
1. Add more diverse sources to the corpus
2. Implement advanced evaluation metrics
3. Enhance the user interface
4. Add personalized recommendation features

## ğŸ“ Project Structure

```
Application-of-NLX-LLM-Personal-Learning-Portal/
â”‚
â”œâ”€â”€ README.md                                  # ğŸ“„ Project overview and documentation
â”œâ”€â”€ requirements.txt                           # ğŸ“¦ Python dependencies
â”‚
â”œâ”€â”€ data/                                      # ğŸ“Š Data files
â”‚   â””â”€â”€ learning_corpus.csv                    # 23 curated sources
â”‚
â”œâ”€â”€ src/                                       # ğŸ’» Source code
â”‚   â”œâ”€â”€ rag_pipeline.py                        # Core RAG system implementation
â”‚   â”œâ”€â”€ streamlit_app.py                       # Streamlit web interface
â”‚   â””â”€â”€ ragas_evaluation_v3.py                 # RAGAs evaluation script
â”‚
â”œâ”€â”€ diagrams/                                  # ğŸ“ System architecture
â”‚   â””â”€â”€ system_architecture.md                 # Detailed architecture documentation
â”‚
â”œâ”€â”€ reports/                                   # ğŸ“‘ Documentation and reports
â”‚   â”œâ”€â”€ Final_Report.md                        # Comprehensive final report
â”‚   â”œâ”€â”€ Evaluation_Log_and_Samples.md          # Detailed evaluation with samples
â”‚   â”œâ”€â”€ RAG_Evaluation_and_Improvements.md     # Complete iterative improvement journey
â”‚   â”‚
â”‚   â”œâ”€â”€ Domain_Learning_Goals.md               # Domain definition & learning objectives (Step 1)
â”‚   â””â”€â”€ PLP_Features_To_Adopt.md               # PLP feature analysis (Step 2)
â”‚
â””â”€â”€ ragas_results/                             # ğŸ“ˆ RAGAs evaluation results
    â”œâ”€â”€ ragas_evaluation_results.json          # Final evaluation score (0.857)
    â”œâ”€â”€ ragas_aggregate_results.json           # Aggregated evaluation metrics
    â””â”€â”€ ragas_scores_per_sample.csv            # Per-sample evaluation scores
```

### Directory Organization

**ğŸ“Š `data/`** - Core data files
- `learning_corpus.csv` - 23 curated sources (Academic Papers, Podcasts, Government Resources)

**ğŸ’» `src/`** - Source code (3 files)
- `rag_pipeline.py` - RAG system with hybrid LLM support (OpenAI GPT-4o-mini + Llama 3.2 1B)
- `streamlit_app.py` - Interactive web interface with 4 tabs (Courses, Ask Coach, BMR Calculator, Query History)
- `ragas_evaluation_v3.py` - Automated RAGAs evaluation script

**ğŸ“ `diagrams/`** - System architecture (1 file)
- `system_architecture.md` - Comprehensive architecture documentation with data flow diagrams

**ğŸ“‘ `reports/`** - Documentation (5 files)
- `Final_Report.md` - Complete project report with architecture, evaluation, and reflections
- `Evaluation_Log_and_Samples.md` - RAGAs results and sample queries
- `Domain_Learning_Goals.md` - Learning domain, questions, and objectives (Step 1)
- `PLP_Features_To_Adopt.md` - Analyzed PLP features (Step 2)
- `RAG_Evaluation_and_Improvements.md` - Complete iterative improvement journey (v1.0 â†’ v3.0)

**ğŸ“ˆ `ragas_results/`** - Evaluation results (3 files)
- `ragas_evaluation_results.json` - Final score: 0.857 (Excellent) â­â­â­â­â­
- `ragas_aggregate_results.json` - Aggregated metrics across all samples
- `ragas_scores_per_sample.csv` - Detailed per-sample evaluation scores

## ğŸ“„ License

Academic project - see assignment guidelines for usage terms.

---

**FitScience Coach** - Making evidence-based fitness and nutrition accessible to everyone! ğŸ‹ï¸â€â™€ï¸ğŸ’ª
